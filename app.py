import os.path

import gradio as gr

from gpuhunter.autodl_client import FailedError, autodl_client
from gpuhunter.data_object import RegionList, Config
from main import LOGS_DIR

css = """
.block.error-message { padding: var(--block-padding); }
.block.error-message p { color: var(--error-icon-color); font-weight: bold; margin: 0; }
"""
with gr.Blocks(title="AutoDL GPU Hunter", theme=gr.themes.Default(text_size="lg"), css=css) as demo:
    gr.Markdown(
        """
        # ğŸ’ AutoDL GPU Hunter
        è¿™æ˜¯ä¸€ä¸ªå¡è¹²è¹²ï¼å¸®ä½ è¹²å®ˆ AutoDL æ˜¾å¡ä¸»æœºï¼Œè¯·è®¾ç½®ä»¥ä¸‹å‚æ•°å¼€å§‹è¹²å®ˆã€‚å®˜ç½‘é“¾æ¥ï¼š[ç®—åŠ›å¸‚åœº](https://www.autodl.com/market/list)
        | [å®¹å™¨å®ä¾‹](https://www.autodl.com/console/instance/list)
        """
    )

    with gr.Group(visible=False) as gr_token_input_group:
        gr_token_input = gr.Textbox(label="å¼€å‘è€… Token", lines=2,
                                    info="æœ¬ Token ä»¥æ˜æ–‡ JSON æ ¼å¼ä¿å­˜åœ¨è¿è¡Œæœ¬ç¨‹åºçš„æœåŠ¡å™¨ä¸Šï¼Œ"
                                         "åˆ‡å‹¿åœ¨ä¸ä¿¡ä»»çš„æœåŠ¡å™¨ä¸Šå¡«å†™ä½ çš„ Tokenï¼Œå¦åˆ™ä¼šè¢«äººç›—ç”¨è´¦å·è€Œé€ æˆæ„å¤–æŸå¤±ï¼",
                                    placeholder="è·å–æ–¹æ³•ï¼šè¿›å…¥ AutoDL ç½‘ç«™ / æ§åˆ¶å° / è´¦å· / è®¾ç½® / å¼€å‘è€… Token")
        gr_token_input_error = gr.Markdown(elem_classes=["error-message"], visible=False)
        gr_token_save_button = gr.Button("ç¡®å®š", variant="primary", size="lg")

    with gr.Group(visible=False) as gr_token_view_group:
        gr_token_view_input = gr.Textbox(label="å¼€å‘è€… Token", lines=1, interactive=False)
        gr_token_clear_button = gr.Button("é€€å‡º", variant="secondary", size="sm")

    with gr.Tab("ğŸŒ² å¼€å§‹è¹²å®ˆ", visible=False) as gr_config_tab:
        with gr.Group():
            gr_gpu_type = gr.CheckboxGroup(["RTX 4090 (28)", "RTX 3090", "RTX 4090"], label="æ˜¾å¡å‹å·", info="")
            gr_region = gr.CheckboxGroup(["è¥¿åŒ—BåŒº (12)", "åŒ—äº¬BåŒº (0)"], label="åœ°åŒº", info="")
            gr_gpu_num = gr.Radio(choices=[n for n in range(1, 13)], label="GPU æ•°é‡", value=1)

        with gr.Row():
            with gr.Column():
                gr_instance_num = gr.Slider(label="ç§Ÿç”¨ GPU ä¸»æœºæ•°é‡", info="å¯é€‰æ‹© 1-10 å°")
                gr_image_category = gr.Radio(choices=["åŸºç¡€é•œåƒ", "ç¤¾åŒºé•œåƒ", "æˆ‘çš„é•œåƒ"], label="å¯åŠ¨é•œåƒ")
                with gr.Group() as gr_base_image_group:
                    with gr.Row():
                        gr_base_image_framework_name = gr.Dropdown(
                            choices=["AUTOMATIC1111/stable-diffusion-webui/tzwm_sd_webui_A1111 / v18"],
                            show_label=False, info="æ¡†æ¶åç§°")
                        gr_base_image_framework_version = gr.Dropdown(
                            choices=["AUTOMATIC1111/stable-diffusion-webui/tzwm_sd_webui_A1111 / v18"],
                            show_label=False, info="æ¡†æ¶ç‰ˆæœ¬")
                    with gr.Row():
                        gr_base_image_python_version = gr.Dropdown(
                            choices=["AUTOMATIC1111/stable-diffusion-webui/tzwm_sd_webui_A1111 / v18"],
                            show_label=False, info="Python ç‰ˆæœ¬")
                        gr_base_image_cuda_version = gr.Dropdown(
                            choices=["AUTOMATIC1111/stable-diffusion-webui/tzwm_sd_webui_A1111 / v18"],
                            show_label=False, info="Cuda ç‰ˆæœ¬")
                with gr.Group() as gr_shared_image_group:
                    gr.Dropdown(choices=["AUTOMATIC1111/stable-diffusion-webui/tzwm_sd_webui_A1111 / v18"],
                                show_label=False, info="æ¡†æ¶åç§°")
                with gr.Group() as gr_private_image_group:
                    gr.Dropdown(choices=["AUTOMATIC1111/stable-diffusion-webui/tzwm_sd_webui_A1111 / v18"],
                                show_label=False, info="æ¡†æ¶åç§°")

                with gr.Accordion("æ‰©å®¹æ•°æ®ç›˜ï¼š50 GB", open=False) as gr_expand_disk_accordion:
                    gr_expand_disk_gb = gr.Slider(info="å¯é€‰æ‹©å®¹é‡èŒƒå›´ 0-60 GB", show_label=False)

                with gr.Accordion("å¤åˆ¶å·²æœ‰å®ä¾‹ï¼šadc5a6cc5a446a", open=False) as gr_clone_instance_accordion:
                    gr_clone_instance_uuid = gr.Dropdown(
                        choices=["AUTOMATIC1111/stable-diffusion-webui/tzwm_sd_webui_A1111 / v18"],
                        show_label=False, info="é€‰æ‹©è¦å¤åˆ¶çš„å®ä¾‹")

            with gr.Column():
                with gr.Accordion("å®šæ—¶å…³æœºï¼šä»Šå¤© 23:59", open=False) as gr_shutdown_time_accordion:
                    gr_shutdown_time_type = gr.Radio(choices=["ä»Šå¤© 23:59", "8 å°æ—¶", "12 å°æ—¶", "24 å°æ—¶", "ä¸å…³æœº"],
                                                     label="å®šæ—¶å…³æœº",
                                                     info="åˆ›å»ºå®ä¾‹æ—¶è‡ªåŠ¨è®¾ç½®å®šæ—¶å…³æœºï¼Œé˜²æ­¢å¿˜è®°å…³é—­åäº§ç”Ÿè´¹ç”¨ã€‚")

                with gr.Accordion("é‚®ä»¶é€šçŸ¥ï¼šzhangsan@lisi.com", open=False) as gr_email_notify_accordion:
                    with gr.Row(equal_height=True):
                        with gr.Group():
                            gr_email_notify_sender = gr.Textbox(label="å‘ä¿¡é‚®ç®±", type="email")
                            gr_email_notify_smtp_password = gr.Textbox(label="å‘ä¿¡é‚®ç®±ç™»å½•å¯†ç ", type="password")
                            gr_email_notify_smtp_server = gr.Textbox(label="SMTP æœåŠ¡å™¨")
                        with gr.Column():
                            gr_email_notify_receipt = gr.Textbox(label="æ”¶ä¿¡é‚®ç®±", type="email",
                                                                 info="å¯ä»¥ç”¨æ”¶ä¿¡é‚®ç®±è‡ªå·±å‘ç»™è‡ªå·±")
                            gr_email_notify_send_button = gr.Button("å‘é€æµ‹è¯•é‚®ä»¶", size="sm")
                            gr_email_notify_send_output = gr.Markdown("## å‘é€æˆåŠŸï¼")

                with gr.Accordion("æ›´å¤šé€‰é¡¹", open=False):
                    gr_scan_interval = gr.Slider(minimum=1, maximum=60, value=10, step=1, label="æ‰«æé—´éš”æ—¶é—´",
                                                 info="å¦‚æœä¸æ˜¯æ€¥éœ€ï¼Œè¯·è®¾ç½®é•¿ä¸€ç‚¹çš„æ—¶é—´ï¼Œæ˜¾å¡ç©ºå‡ºæ¥ä¹Ÿéœ€è¦æ—¶é—´ï¼ŒåŒæ—¶è¯·é¿å…ç»™ AutoDL.com å¢åŠ å‹åŠ›ã€‚")
                    gr_shutdown_hunter_after_success = gr.Radio(choices=["å…³æœº", "ä¸å…³æœº"],
                                                                label="å®ˆåˆ°åå°† Hunter å…³æœº",
                                                                info="æˆåŠŸåå…³é—­è¿è¡Œæ­¤ç¨‹åº (AutoDL GPU Hunter) çš„æœºå™¨ï¼Œé˜²æ­¢é‡å¤è¹²å®ˆæµªè´¹èµ„æºã€‚")

        gr_hunt_start_button = gr.Button("ğŸ™ˆ ç°åœ¨å¼€å§‹", variant="primary", size="lg")
        gr_hunt_stop_button = gr.Button("ğŸ¤š åœæ­¢", variant="stop", size="lg")
        gr_hunt_logs = gr.Textbox(label="ğŸ™‰ æ­£åœ¨è¹²å®ˆ", autoscroll=True, lines=10)


        def read_output_logs():
            with open(os.path.join(LOGS_DIR, "output.log"), "r") as f:
                return f.read()


        # def load_stat(gpu_type_names=None, region_list=None):
        #     region_list = region_list or RegionList().load()
        #     gpu_type_names = gpu_type_names or [
        #         "RTX 4090",
        #         "RTX 3090",
        #         "RTX 3080 Ti",
        #         "RTX 3080",
        #         "RTX 3060",
        #     ]
        #     return {
        #         **update_matrix(gpu_type_names),
        #         gr_gpu_checkbox_group: gr.CheckboxGroup(choices=region_list.get_gpu_type_names(), value=gpu_type_names),
        #         gr_stat_note: gr.Markdown(f"ä»¥ä¸Šæ˜¯å½“å‰ AutoDL å®˜ç½‘æŸ¥è¯¢åˆ°çš„ GPU ä¸»æœºæ•°é‡ï¼Œ"
        #                                   f'æ›´æ–°æ—¶é—´ï¼š{region_list.modified_time.strftime("%Y-%m-%d %H:%M:%S")}ã€‚'),
        #     }

        demo.load(read_output_logs, None, gr_hunt_logs, every=1)

        # ç«‹å³ç§Ÿç”¨ï¼š
        #   å®šæ—¶å…³æœºï¼šç¬¬äºŒå¤©0ç‚¹  ç§Ÿç”¨xxxåˆ†é’Ÿå  ä¸è®¾ç½®
        #   å¤åˆ¶å·²æœ‰å®ä¾‹ï¼š
        #   ç§Ÿç”¨æ•°é‡ï¼š3
        # é‚®ä»¶é€šçŸ¥ï¼šæ¥å—é€šçŸ¥çš„é‚®ç®±ï¼Œéœ€è¦å‘é€æµ‹è¯•é‚®ä»¶çš„åŠŸèƒ½

        # æ—¶é—´é—´éš”ï¼š1åˆ†é’Ÿï¼Œ10åˆ†é’Ÿï¼ˆé»˜è®¤ï¼‰ï¼Œ30åˆ†é’Ÿï¼Œ60åˆ†é’Ÿã€‚ï¼ˆå¦‚æœä¸æ˜¯æ€¥éœ€ï¼Œè¯·è®¾ç½®é•¿ä¸€ç‚¹çš„æ—¶é—´ï¼Œé¿å…ç»™ autodl å¢åŠ å‹åŠ›ï¼‰
        # ğŸ™ˆ ç°åœ¨å¼€å§‹ï¼ŒğŸ™‰ æ­£åœ¨è¹²å®ˆï¼ˆé£é™©æç¤ºï¼‰
        # outputï¼š
        #   æš‚æ—¶è¿˜æ²¡æœ‰ç©ºé—²çš„ GPU ä¸»æœºã€‚
        #   å‘ç° GPU ä¸»æœºï¼šè¥¿åŒ—BåŒºï¼ŒRTX 4090ï¼Œç«‹å³ç§Ÿç”¨
        #   å½“å‰å·²å¯åŠ¨ 4 ä¸ªå®¹å™¨å®ä¾‹
        #   2024-03-02 15:03:34
        # å®ˆåˆ°åå…³æœº

    with gr.Tab("ğŸ° ç®—åŠ›å®å†µ", visible=False) as gr_stat_tab:
        gr.Markdown("## å½“å‰ GPU ä¸»æœºæ•°é‡")
        gr_gpu_checkbox_group = gr.CheckboxGroup([], label="æ˜¾å¡å‹å·")
        gr_gpu_region_matrix = gr.Matrix()
        with gr.Row():
            with gr.Column(scale=8):
                gr_stat_note = gr.Markdown()
            with gr.Column(scale=2):
                gr_stat_refresh_button = gr.Button("ç«‹å³æ›´æ–°", size="sm")


        def refresh_stat(gpu_type_names=None):
            region_list = RegionList().update()
            return load_stat(gpu_type_names, region_list)


        def load_stat(gpu_type_names=None, region_list=None):
            region_list = region_list or RegionList().load()
            gpu_type_names = gpu_type_names or [
                "RTX 4090",
                "RTX 3090",
                "RTX 3080 Ti",
                "RTX 3080",
                "RTX 3060",
            ]
            return {
                **update_matrix(gpu_type_names),
                gr_gpu_checkbox_group: gr.CheckboxGroup(choices=region_list.get_gpu_type_names(), value=gpu_type_names),
                gr_stat_note: gr.Markdown(f"ä»¥ä¸Šæ˜¯å½“å‰ AutoDL å®˜ç½‘æŸ¥è¯¢åˆ°çš„ GPU ä¸»æœºæ•°é‡ï¼Œ"
                                          f'æ›´æ–°æ—¶é—´ï¼š{region_list.modified_time.strftime("%Y-%m-%d %H:%M:%S")}ã€‚'),
            }


        def update_matrix(gpu_type_names):
            region_list = RegionList().load()
            return {
                gr_gpu_region_matrix: gr.Matrix(headers=["åœ°åŒº"] + [n for n in gpu_type_names], value=[
                    [r["region_name"]] + [
                        region_list.get_region_stats([gn], [r["region_name"]])[0]["idle_gpu_num"] or ""
                        for gn in gpu_type_names
                    ]
                    for r in region_list.get_region_stats()
                ]),
            }


        gr_gpu_checkbox_group.change(update_matrix, inputs=[gr_gpu_checkbox_group], outputs=[gr_gpu_region_matrix],
                                     show_progress="hidden")
        gr_stat_refresh_button.click(refresh_stat, inputs=[gr_gpu_checkbox_group],
                                     outputs=[gr_gpu_checkbox_group, gr_gpu_region_matrix, gr_stat_note])
        demo.load(load_stat, outputs=[gr_gpu_checkbox_group, gr_gpu_region_matrix, gr_stat_note])


    def load_config(config=None):
        if config is None:
            config = Config().load()
        if config.token:
            try:
                RegionList().update()
            except FailedError as e:
                error_message = str(e)
                if "ç™»å½•å¤±è´¥ï¼Œè¯·é‡è¯•" in error_message:
                    error_message = "ç™»å½•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ Token åé‡è¯•ã€‚"
                elif "ç™»é™†è¶…æ—¶" in error_message:
                    error_message = "ç™»å½•è¶…æ—¶ï¼Œè¯·å…ˆæ‰“å¼€ AutoDL.com å®˜ç½‘ç™»å½•ä¸€ä¸‹è´¦å·ï¼Œç„¶åè¿”å›å¹¶ç‚¹å‡»ç¡®å®šã€‚"
                return {
                    gr_token_input_group: gr.Group(visible=True),
                    gr_token_view_group: gr.Group(visible=False),
                    gr_token_input: gr.Textbox(value=config.token),
                    gr_token_input_error: gr.Markdown(visible=True, value=error_message),
                }
            return {
                gr_token_input_group: gr.Group(visible=False),
                gr_token_view_group: gr.Group(visible=True),
                gr_token_view_input: config.token[:6] + "******" + config.token[-6:],
                gr_config_tab: gr.Tab(visible=True),
                gr_stat_tab: gr.Tab(visible=True),
                gr_token_input_error: gr.Markdown(visible=False),
            }
        else:
            return {
                gr_token_input_group: gr.Group(visible=True),
                gr_token_view_group: gr.Group(visible=False),
                gr_token_input: gr.Textbox(value=""),
                gr_config_tab: gr.Tab(visible=False),
                gr_stat_tab: gr.Tab(visible=False),
            }


    def save_token(token):
        config = Config().load()
        config.token = token
        config.save()
        autodl_client.load_config()
        return load_config(config)


    def clear_token():
        return save_token("")


    demo.load(load_config, outputs=[gr_token_input_group, gr_token_input, gr_token_input_error,
                                    gr_token_view_group, gr_token_view_input, gr_config_tab, gr_stat_tab])

    gr_token_save_button.click(save_token, inputs=[gr_token_input],
                               outputs=[gr_token_input_group, gr_token_input, gr_token_input_error,
                                        gr_token_view_group, gr_token_view_input, gr_config_tab, gr_stat_tab])
    gr_token_clear_button.click(clear_token,
                                outputs=[gr_token_input_group, gr_token_input, gr_token_input_error,
                                         gr_token_view_group, gr_token_view_input, gr_config_tab, gr_stat_tab])

if __name__ == "__main__":
    demo.launch()
